# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /trainer: gpu
  - override /data: grass
  - override /model: unetmobv2
  - override /logger: tensorboard
  - override /callbacks: default

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["grasseg", "unetmobv2"]

seed: 42


logger:
  wandb:
    project: "grasseg"
    name: "unetmobv2"

callbacks:
  model_checkpoint:
    dirpath: ${paths.output_dir}/checkpoints
    filename: "epoch_{epoch:03d}"
    monitor: "val/loss"
    mode: "min"
    save_last: True
    auto_insert_metric_name: False

model:
  scheduler:
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    _partial_: true
    mode: min
    factor: 0.5
    patience: 10