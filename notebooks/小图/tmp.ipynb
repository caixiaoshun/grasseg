{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import OrderedDict\n",
    "from glob import glob\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "import torchvision\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "from rich.progress import track\n",
    "from src.utils.draw import pasteImages, give_colors_to_mask\n",
    "from src.data.components.grass import Grass\n",
    "from src.utils.draw import pasteImages, give_colors_to_mask\n",
    "from src.data.components.grass import Grass\n",
    "from src.models.components.farseg import Farseg\n",
    "from src.models.components.fcn import FCN\n",
    "from src.models.components.linknet import Linknet\n",
    "from src.models.components.pspnet import PSPNet\n",
    "from src.models.components.unet_plus_plus import UnetPlusPlus\n",
    "from src.models.components.pan import PAN\n",
    "from src.models.components.unet import Unet\n",
    "from src.models.components.deeplabv3plus import DeepLabV3Plus\n",
    "from src.models.components.manet import MAnet\n",
    "from src.models.components.fpn import FPN\n",
    "from src.models.components.deeplabv3 import DeepLabV3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = OrderedDict(\n",
    "            {\n",
    "                \"linknet-timm-resnest101e\": Linknet(encoder_name=\"timm-resnest101e\").to(\n",
    "                    device\n",
    "                ),\n",
    "                \"fpn-timm-regnetx_320\": FPN(encoder_name=\"timm-regnetx_320\").to(\n",
    "                    device\n",
    "                ),\n",
    "                \"manet-se_resnext101_32x4d\": MAnet(\n",
    "                    encoder_name=\"se_resnext101_32x4d\"\n",
    "                ).to(device),\n",
    "                \"deeplabv3plus-timm-efficientnet-l2\": DeepLabV3Plus(\n",
    "                    encoder_name=\"timm-efficientnet-l2\",encoder_weights=\"noisy-student-475\"\n",
    "                ).to(device),\n",
    "                \"farseg_resnet50\": Farseg(backbone=\"resnet50\").to(device),\n",
    "                \"unet-timm-efficientnet-l2\": Unet(\n",
    "                    encoder_name=\"timm-efficientnet-l2\",encoder_weights=\"noisy-student-475\"\n",
    "                ).to(device),\n",
    "                \"pan-se_resnext101_32x4d\": PAN(encoder_name=\"se_resnext101_32x4d\").to(\n",
    "                    device\n",
    "                ),\n",
    "                \"unet_plus_plus-se_resnext101_32x4d\": UnetPlusPlus(\n",
    "                    encoder_name=\"se_resnext101_32x4d\"\n",
    "                ).to(device),\n",
    "                \"fcn-resnet50\": FCN(weights=\"resnet50\",num_classes=6).to(device),\n",
    "                \"pspnet-timm-efficientnet-l2\": PSPNet(\n",
    "                    encoder_name=\"timm-efficientnet-l2\",encoder_weights=\"noisy-student-475\"\n",
    "                ).to(device),\n",
    "                \"deeplabv3-resnet152\": DeepLabV3(encoder_name=\"resnet152\").to(\n",
    "                    device\n",
    "                ),\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state_dict(filename: str):\n",
    "    ckpt = torch.load(filename, map_location=device)\n",
    "    state_dict = {}\n",
    "    for k, v in ckpt[\"state_dict\"].items():\n",
    "        state_dict[k[4:]] = v\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    filename = glob(f\"../logs/grasseg/{name}/*/checkpoints/*epoch*.ckpt\")[0]\n",
    "    model.load_state_dict(load_state_dict(filename))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import numpy as np\n",
    "\n",
    "from skimage import exposure\n",
    "import cv2\n",
    "\n",
    "# # 读取图像\n",
    "# image = tifffile.imread('rgb_point1.tif')\n",
    "\n",
    "# # 对各通道分别进行直方图均衡化\n",
    "# equalized_image = np.zeros_like(image)\n",
    "# for i in range(3):\n",
    "#     equalized_image[..., i] = exposure.equalize_hist(image[..., i]) * 255\n",
    "\n",
    "# image1 = equalized_image.astype(np.uint8)\n",
    "\n",
    "# # 目标尺寸\n",
    "# target_height, target_width = 256, 256\n",
    "\n",
    "# # 计算需要补零的上下左右数量\n",
    "# pad_top = (target_height - image.shape[0]) // 2\n",
    "# pad_bottom = target_height - image.shape[0] - pad_top\n",
    "# pad_left = (target_width - image.shape[1]) // 2\n",
    "# pad_right = target_width - image.shape[1] - pad_left\n",
    "\n",
    "# # 使用 numpy 的 pad 函数进行四周补零\n",
    "# image1 = np.pad(image1, ((pad_top, pad_bottom), (pad_left, pad_right), (0, 0)), mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(image1.shape,np.min(image1),np.max(image1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_image(filename:str):\n",
    "#     image = tf.imread(filename)\n",
    "#     image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "#     image = (image * 255).astype(np.uint8)\n",
    "#     return Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image1 = tf.imread(\"rgb_point1.tif\")\n",
    "# print(image1.shape,np.min(image1),np.max(image1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# plt.imshow(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(filename:str):\n",
    "\n",
    "    # 读取图像\n",
    "    image = tifffile.imread(filename)\n",
    "\n",
    "    # 对各通道分别进行直方图均衡化\n",
    "    equalized_image = np.zeros_like(image)\n",
    "    for i in range(3):\n",
    "        equalized_image[..., i] = exposure.equalize_hist(image[..., i]) * 255\n",
    "\n",
    "    image = equalized_image.astype(np.uint8)\n",
    "\n",
    "    # 目标尺寸\n",
    "    target_height, target_width = 256, 256\n",
    "\n",
    "    # 计算需要补零的上下左右数量\n",
    "    pad_top = (target_height - image.shape[0]) // 2\n",
    "    pad_bottom = target_height - image.shape[0] - pad_top\n",
    "    pad_left = (target_width - image.shape[1]) // 2\n",
    "    pad_right = target_width - image.shape[1] - pad_left\n",
    "    # 使用 numpy 的 pad 函数进行四周补零\n",
    "    image = np.pad(image, ((pad_top, pad_bottom), (pad_left, pad_right), (0, 0)), mode='constant', constant_values=0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_top = (256 - 12) // 2\n",
    "pad_bottom = 256 - 12 - pad_top\n",
    "pad_left = (256 - 12) // 2\n",
    "pad_right = 256 - 12 - pad_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def inference(model:nn.Module,img: torch.Tensor) -> np.ndarray:\n",
    "    logits = model(img)\n",
    "    preds = torch.argmax(logits, dim=1).squeeze().cpu().numpy()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(mask:np.ndarray,pix:int,ratio:float):\n",
    "    mask_pix = np.sum(mask==pix)\n",
    "    num = mask_pix / 144\n",
    "    return ratio * num\n",
    "\n",
    "\n",
    "def get_mask(model:nn.Module,image: np.ndarray,model_name:str,image_name) -> None:\n",
    "    img = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "    img = torch.from_numpy(img).unsqueeze(0).float().permute(0, 3, 1, 2).to(\"cuda:1\")\n",
    "    mask = inference(model,img)\n",
    "    color_mask = give_colors_to_mask(image,mask)\n",
    "    restored_image = image[pad_top:pad_top+12, pad_left:pad_left+12, :]\n",
    "    color_mask = color_mask[pad_top:pad_top+12, pad_left:pad_left+12, :]\n",
    "    paste_image = pasteImages([restored_image,color_mask])\n",
    "    show_image = Image.fromarray(paste_image)\n",
    "    show_image.save(f\"./results/{image_name}/{model_name}.png\",dpi=(300,300))\n",
    "\n",
    "    mask_clip = mask[pad_top:pad_top+12, pad_left:pad_left+12]\n",
    "\n",
    "    res = [compute(mask_clip,5,0.9),\n",
    "    compute(mask_clip,4,0.6),\n",
    "    compute(mask_clip,3,0.3),\n",
    "    compute(mask_clip,2,0.15),\n",
    "    compute(mask_clip,1,0.05)]\n",
    "    print(f\"{model_name}:植被覆盖度:{sum(res)}\")\n",
    "\n",
    "    return show_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images/rgb_point4.tif is processing...\n",
      "linknet-timm-resnest101e:植被覆盖度:0.04027777777777778\n",
      "fpn-timm-regnetx_320:植被覆盖度:0.08541666666666667\n",
      "manet-se_resnext101_32x4d:植被覆盖度:0.08750000000000001\n",
      "deeplabv3plus-timm-efficientnet-l2:植被覆盖度:0.04097222222222222\n",
      "farseg_resnet50:植被覆盖度:0.0\n",
      "unet-timm-efficientnet-l2:植被覆盖度:0.5211805555555555\n",
      "pan-se_resnext101_32x4d:植被覆盖度:0.0\n",
      "unet_plus_plus-se_resnext101_32x4d:植被覆盖度:0.011458333333333334\n",
      "fcn-resnet50:植被覆盖度:0.23888888888888887\n",
      "pspnet-timm-efficientnet-l2:植被覆盖度:0.0\n",
      "deeplabv3-resnet152:植被覆盖度:0.5572916666666665\n",
      "./images/rgb_point3.tif is processing...\n",
      "linknet-timm-resnest101e:植被覆盖度:0.07361111111111111\n",
      "fpn-timm-regnetx_320:植被覆盖度:0.196875\n",
      "manet-se_resnext101_32x4d:植被覆盖度:0.2829861111111111\n",
      "deeplabv3plus-timm-efficientnet-l2:植被覆盖度:0.5517361111111111\n",
      "farseg_resnet50:植被覆盖度:0.08541666666666667\n",
      "unet-timm-efficientnet-l2:植被覆盖度:0.9\n",
      "pan-se_resnext101_32x4d:植被覆盖度:0.0\n",
      "unet_plus_plus-se_resnext101_32x4d:植被覆盖度:0.04583333333333334\n",
      "fcn-resnet50:植被覆盖度:0.08541666666666667\n",
      "pspnet-timm-efficientnet-l2:植被覆盖度:0.80625\n",
      "deeplabv3-resnet152:植被覆盖度:0.20729166666666668\n",
      "./images/rgb_point8.tif is processing...\n",
      "linknet-timm-resnest101e:植被覆盖度:0.05590277777777778\n",
      "fpn-timm-regnetx_320:植被覆盖度:0.18125\n",
      "manet-se_resnext101_32x4d:植被覆盖度:0.26458333333333334\n",
      "deeplabv3plus-timm-efficientnet-l2:植被覆盖度:0.4690972222222223\n",
      "farseg_resnet50:植被覆盖度:0.06770833333333333\n",
      "unet-timm-efficientnet-l2:植被覆盖度:0.9\n",
      "pan-se_resnext101_32x4d:植被覆盖度:0.010416666666666668\n",
      "unet_plus_plus-se_resnext101_32x4d:植被覆盖度:0.05\n",
      "fcn-resnet50:植被覆盖度:0.07951388888888888\n",
      "pspnet-timm-efficientnet-l2:植被覆盖度:0.9\n",
      "deeplabv3-resnet152:植被覆盖度:0.16041666666666668\n",
      "./images/rgb_point6.tif is processing...\n",
      "linknet-timm-resnest101e:植被覆盖度:0.09131944444444445\n",
      "fpn-timm-regnetx_320:植被覆盖度:0.1708333333333333\n",
      "manet-se_resnext101_32x4d:植被覆盖度:0.13194444444444445\n",
      "deeplabv3plus-timm-efficientnet-l2:植被覆盖度:0.3111111111111111\n",
      "farseg_resnet50:植被覆盖度:0.07951388888888888\n",
      "unet-timm-efficientnet-l2:植被覆盖度:0.9\n",
      "pan-se_resnext101_32x4d:植被覆盖度:0.006597222222222223\n",
      "unet_plus_plus-se_resnext101_32x4d:植被覆盖度:0.046875\n",
      "fcn-resnet50:植被覆盖度:0.13263888888888892\n",
      "pspnet-timm-efficientnet-l2:植被覆盖度:0.9\n",
      "deeplabv3-resnet152:植被覆盖度:0.15520833333333334\n",
      "./images/rgb_point1.tif is processing...\n",
      "linknet-timm-resnest101e:植被覆盖度:0.13263888888888892\n",
      "fpn-timm-regnetx_320:植被覆盖度:0.37916666666666665\n",
      "manet-se_resnext101_32x4d:植被覆盖度:0.24583333333333332\n",
      "deeplabv3plus-timm-efficientnet-l2:植被覆盖度:0.4875\n",
      "farseg_resnet50:植被覆盖度:0.07361111111111111\n",
      "unet-timm-efficientnet-l2:植被覆盖度:0.8895833333333334\n",
      "pan-se_resnext101_32x4d:植被覆盖度:0.008333333333333333\n",
      "unet_plus_plus-se_resnext101_32x4d:植被覆盖度:0.040625\n",
      "fcn-resnet50:植被覆盖度:0.32152777777777775\n",
      "pspnet-timm-efficientnet-l2:植被覆盖度:0.9\n",
      "deeplabv3-resnet152:植被覆盖度:0.30625\n",
      "./images/rgb_point5.tif is processing...\n",
      "linknet-timm-resnest101e:植被覆盖度:0.08541666666666667\n",
      "fpn-timm-regnetx_320:植被覆盖度:0.28541666666666665\n",
      "manet-se_resnext101_32x4d:植被覆盖度:0.27395833333333336\n",
      "deeplabv3plus-timm-efficientnet-l2:植被覆盖度:0.4041666666666667\n",
      "farseg_resnet50:植被覆盖度:0.103125\n",
      "unet-timm-efficientnet-l2:植被覆盖度:0.9\n",
      "pan-se_resnext101_32x4d:植被覆盖度:0.0006944444444444445\n",
      "unet_plus_plus-se_resnext101_32x4d:植被覆盖度:0.030208333333333334\n",
      "fcn-resnet50:植被覆盖度:0.22708333333333333\n",
      "pspnet-timm-efficientnet-l2:植被覆盖度:0.9\n",
      "deeplabv3-resnet152:植被覆盖度:0.24375000000000002\n",
      "./images/rgb_point2.tif is processing...\n",
      "linknet-timm-resnest101e:植被覆盖度:0.07951388888888888\n",
      "fpn-timm-regnetx_320:植被覆盖度:0.17604166666666665\n",
      "manet-se_resnext101_32x4d:植被覆盖度:0.2857638888888889\n",
      "deeplabv3plus-timm-efficientnet-l2:植被覆盖度:0.38506944444444446\n",
      "farseg_resnet50:植被覆盖度:0.05\n",
      "unet-timm-efficientnet-l2:植被覆盖度:0.9\n",
      "pan-se_resnext101_32x4d:植被覆盖度:0.0\n",
      "unet_plus_plus-se_resnext101_32x4d:植被覆盖度:0.03229166666666667\n",
      "fcn-resnet50:植被覆盖度:0.09722222222222221\n",
      "pspnet-timm-efficientnet-l2:植被覆盖度:0.8625\n",
      "deeplabv3-resnet152:植被覆盖度:0.18125\n",
      "./images/rgb_point7.tif is processing...\n",
      "linknet-timm-resnest101e:植被覆盖度:0.04826388888888889\n",
      "fpn-timm-regnetx_320:植被覆盖度:0.09270833333333334\n",
      "manet-se_resnext101_32x4d:植被覆盖度:0.043750000000000004\n",
      "deeplabv3plus-timm-efficientnet-l2:植被覆盖度:0.06979166666666667\n",
      "farseg_resnet50:植被覆盖度:0.0034722222222222225\n",
      "unet-timm-efficientnet-l2:植被覆盖度:0.46770833333333334\n",
      "pan-se_resnext101_32x4d:植被覆盖度:0.0\n",
      "unet_plus_plus-se_resnext101_32x4d:植被覆盖度:0.001388888888888889\n",
      "fcn-resnet50:植被覆盖度:0.22118055555555557\n",
      "pspnet-timm-efficientnet-l2:植被覆盖度:0.012499999999999999\n",
      "deeplabv3-resnet152:植被覆盖度:0.5795138888888889\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "images = glob(\"./images/*.tif\")\n",
    "for filename in images:\n",
    "    image = read_image(filename)\n",
    "    image_name = filename.split(os.path.sep)[-1].split(\".\")[0]\n",
    "    print(f\"{filename} is processing...\")\n",
    "    os.makedirs(f\"./results/{image_name}\",exist_ok=True)\n",
    "    for model_name,model in models.items():\n",
    "        get_mask(model,image,model_name,image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 deeplabv3plus-timm-efficientnet-l2\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
